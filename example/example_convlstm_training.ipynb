{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Example script: training and predicting with ConvLSTM\n",
    "Author          : SSI project team Wadden Sea <br>\n",
    "First Built     : 2021.08.01 <br>\n",
    "Last Update     : 2021.08.12 <br>\n",
    "Description     : This notebook serves as an example of training and predicting with\n",
    "                  Convolutional Long-Short Term Memeory Neural Network (ConvLSTM). <br>\n",
    "Dependency      : os, numpy, pytorch <br>\n",
    "Return Values   : time series / array <br>\n",
    "Caveat!         : This module performs many-to-one prediction! It supports CUDA. <br>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# import convlstm\n",
    "sys.path.append(\"../src\")\n",
    "import convlstm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Path"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# please specify output path for the model\n",
    "output_path = './model'\n",
    "if not os.path.exists(output_path):\n",
    "   os.makedirs(output_path, exist_ok = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyper-parameter of neural network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "input_channels = 6 # number of input channels e.g. concentration heatmap, current, wind curl, etc.\n",
    "hidden_channels = [6, 3, 1] # the last digit is the output channel\n",
    "kernel_size = 3\n",
    "batch_size = 1\n",
    "learning_rate = 0.01\n",
    "num_epochs = 20"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hardware info and version of pytorch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print (\"Pytorch version {}\".format(torch.__version__))\n",
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use GPU if possible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device to be used for computation: {}\".format(device))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pytorch version 1.8.1\n",
      "Device to be used for computation: cpu\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# initialize our model\n",
    "model = convlstm.ConvLSTM(input_channels, hidden_channels, kernel_size).to(device)\n",
    "# choose loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "# choose optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# check the model / loss function and optimizer\n",
    "print(model)\n",
    "print(loss_fn)\n",
    "print(optimizer)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ConvLSTM(\n",
      "  (cell0): ConvLSTMCell(\n",
      "    (Wxi): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whi): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxf): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whf): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxc): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whc): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxo): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Who): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (cell1): ConvLSTMCell(\n",
      "    (Wxi): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whi): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxf): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whf): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxc): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whc): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxo): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Who): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (cell2): ConvLSTMCell(\n",
      "    (Wxi): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whi): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxf): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whf): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxc): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whc): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxo): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Who): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create dummy data for testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# training data\n",
    "train_X_torch = Variable(torch.randn(10, 6, 5, 5)).to(device) # shape [timestep, channel, height, width]\n",
    "train_y_torch = Variable(torch.randn(10, 6, 5, 5)).float().to(device)\n",
    "# testing data\n",
    "test_X_torch = Variable(torch.randn(2, 6, 5, 5)).to(device) # shape [timestep, channel, height, width]\n",
    "test_y_torch = Variable(torch.randn(2, 6, 5, 5)).float().to(device)\n",
    "# get length of training set\n",
    "train_steps, channels, height, width = train_X_torch.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "hist = np.zeros(num_epochs) # save the loss for every epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # Clear stored gradient\n",
    "    model.zero_grad()\n",
    "    # loop through all timesteps\n",
    "    for t in range(train_steps):\n",
    "        var_X = torch.autograd.Variable(train_X_torch[t,:,:,:].view(-1,channels,height,width)).to(device) # record gradient\n",
    "        var_y = torch.autograd.Variable(train_y_torch[t,:,:,:].view(-1,1,height,width)).to(device) # record gradient\n",
    "        # Forward process\n",
    "        pred_y, _ = model(var_X, t)\n",
    "        # compute loss\n",
    "        if t == 0:\n",
    "            loss = loss_fn(pred_y, var_y)\n",
    "        else:\n",
    "            loss += loss_fn(pred_y, var_y)\n",
    "    if epoch % 2 == 0:\n",
    "        print(\"Epoch \", epoch, \"MSE: \", loss.item())\n",
    "    hist[epoch] = loss.item()\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "# save the general checkpoint\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item()\n",
    "            }, os.path.join(output_path,'Lagrangian_ML_training_checkpoint.pt'))\n",
    "print(\"The checkpoint of the model and training status is saved.\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/yangliu/miniconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([6, 1, 5, 5])) that is different to the input size (torch.Size([1, 1, 5, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch  0 MSE:  10.254456520080566\n",
      "Epoch  2 MSE:  10.23924732208252\n",
      "Epoch  4 MSE:  10.231311798095703\n",
      "Epoch  6 MSE:  10.17760181427002\n",
      "Epoch  8 MSE:  10.135177612304688\n",
      "Epoch  10 MSE:  10.110885620117188\n",
      "Epoch  12 MSE:  10.123470306396484\n",
      "Epoch  14 MSE:  9.997820854187012\n",
      "Epoch  16 MSE:  9.983427047729492\n",
      "Epoch  18 MSE:  9.888792037963867\n",
      "The checkpoint of the model and training status is saved.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "90e02b2587fbb2ca467fc85381f5522fddb4a9e5fbb8605712260c849ecf752b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}