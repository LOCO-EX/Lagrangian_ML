{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4c767d-94f0-4fa9-83be-5cbc7ed90718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset -f\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.collections import PolyCollection #for plots polygons as rasters\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta as delta\n",
    "from matplotlib import path\n",
    "from scipy.spatial import KDTree, cKDTree #c implementation is faster (to find nearest neighbor)\n",
    "import os\n",
    "import dask as da\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from scipy.interpolate import griddata #interpolation in space for non-uniform grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4729db31-1ef1-4f7e-9b35-d621a04b84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs----------\n",
    "#path of directories\n",
    "home_dir = \"/export/lv4/user/jfajardourbina/\"\n",
    "dir_vel= f\"{home_dir}dws_ulf_getm_2D_depth_avg/data/velocity/\"\n",
    "dir_dws_bound = f\"{home_dir}dws_ulf_getm_2D_depth_avg/experiments_post_proc/analysis_eulerian_data_36years/data_dws_boundaries/\"\n",
    "savee='everyM2' #saving track data every m2\n",
    "deploy='everyM2'#deploy set of particles every m2\n",
    "minTsim=60 #mimimum time of simulation (days)\n",
    "maxTsim=91 #maximum time of simulation (days)\n",
    "dir_tracks = f\"{home_dir}dws_ulf_getm_2D_depth_avg/experiments_post_proc/lagrangian_simulation_36years/exp-deployHighVolume_coords-xcyc_save-{savee}_deploy-{deploy}_Tsim-{minTsim}-{maxTsim}d/tracks/\"\n",
    "#files\n",
    "files_vel_root=\"RE.DWS200m.uvz.\"\n",
    "file_dws_bound0=\"dws_boundaries_contour0.nc\"; #contour of DWS are the land points closest to ocean points\n",
    "#parameters\n",
    "npa_per_dep=12967 #number of particles per deployment\n",
    "m2=int(12.42*3600+2) #period in seconds\n",
    "dx=400/1e3; dy=400/1e3 #particle grid resolution\n",
    "#\n",
    "#paths for output data\n",
    "dir_post_proc_data=f\"{home_dir}dws_ulf_getm_2D_depth_avg/experiments_post_proc/lagrangian_simulation_36years/machine_learning_github/Lagrangian_ML/post_proc_data/\"\n",
    "dir_net_displacement=\"net_displacement/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "978f2952-32ee-4c39-822b-f91cef273ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open dws boundaries----\n",
    "names_tr=[\"marsdiep\",\"eierlandsgat\",\"vlie\",\"borndiep\",\"pinkegat\",\"watershed1\"]\n",
    "names_islands=[\"coast\",\"texel\",\"vlieland\",\"terschelling\",\"ameland\",\"schiermonnikoog\"]\n",
    "#contour0 (inlets and boundaries along coast and islands)\n",
    "dsb0=xr.open_dataset(dir_dws_bound+file_dws_bound0) #float64\n",
    "bdr_dws0=dsb0.bdr_dws.values #points that define DWS\n",
    "\n",
    "#open any velocity file---\n",
    "year_sim=2009;month_sim=5\n",
    "file_vel_path=f\"{dir_vel}{files_vel_root}{year_sim}{month_sim:02d}01.nc\" #:02d includes leading zeros (at the begin)\n",
    "ds=xr.open_dataset(file_vel_path,chunks={'xc':-1,'yc':-1,'time':110}) #chunks every 36h\n",
    "xc=ds.xc; yc=ds.yc; h=ds.bathymetry.load()\n",
    "mask=h.copy(); mask=xr.where(np.isfinite(mask),1,0) #mask ocean=1, land=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc12b54-03a0-4924-9dd0-895b9bb348c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridding data with nearest neighbor in a extended domain (to avoid problems in boundaries when using convolution)\n",
    "def gridding_particles(var,x0,y0):\n",
    "    xmin=x0.min();xmax=x0.max();ymin=y0.min();ymax=y0.max()\n",
    "    extend_grid=10 #so from particle min max positions extend grid 10*dx (to not have problems with convolution)\n",
    "    xgrid=np.arange(xmin-dx*1e3*extend_grid,xmax+dx*1e3*(extend_grid+1),dx*1e3)\n",
    "    ygrid=np.arange(ymin-dy*1e3*extend_grid,ymax+dy*1e3*(extend_grid+1),dy*1e3)\n",
    "    xgrid0,ygrid0=np.meshgrid(xgrid,ygrid)\n",
    "    valgrid=xgrid0.flatten()*np.nan\n",
    "    tree = cKDTree(np.c_[xgrid0.flatten(),ygrid0.flatten()]) #points in the new extended grid\n",
    "    _,ij = tree.query(np.c_[x0,y0], k=1) #get index for every x0,y0 to put values in the new grid\n",
    "    valgrid[ij]=var\n",
    "    valgrid=np.reshape(valgrid,(len(ygrid),len(xgrid)))\n",
    "    return xgrid0,ygrid0,valgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa791c6c-e3e0-4527-9c88-0f72ea05d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_track_paths=sorted(glob.glob(f'{dir_tracks}/**/*.nc',recursive=True)) \n",
    "year_ini=1980; year_end=2015\n",
    "years=np.arange(year_ini,year_end+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e967571e-514c-4448-8991-1f45e560fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#it takes 10 min for the 36 years\n",
    "for year in years:\n",
    "\n",
    "    print(year)\n",
    "    files_track_paths=sorted(glob.glob(f'{dir_tracks}{year}/*.nc',recursive=True)) \n",
    "\n",
    "    dx_grid=[]; dy_grid=[]\n",
    "    nonan=[]\n",
    "    for i in range(len(files_track_paths)):\n",
    "        #\n",
    "        #print(files_track_paths[i][-68:])\n",
    "        dst0=xr.open_dataset(files_track_paths[i], chunks={'traj': npa_per_dep}) #float32, a bit faster than npa_per_dep*10 when .compute data for this case\n",
    "        dst0.close()\n",
    "        #\n",
    "        #get number of deployments for this month\n",
    "        num_deploys_1m0=int(dict(dst0.dims)['traj']/npa_per_dep)\n",
    "        #ini_dep / end_dep = 0(1st dep), 1(2nd dep), 2...\n",
    "        #it = 0(displacement after M2 from fixed grid ini positions), 1(displacement after 2xM2), ...2\n",
    "        ini_dep=0 #select index of initial deployment\n",
    "        end_dep=num_deploys_1m0-1 #select index of last deployment\n",
    "        it=0 #select 1st displacement for all deployments\n",
    "        #\n",
    "        if i==0:\n",
    "            #build grid (like the one of displacements)\n",
    "            x0=dst0.x.isel(traj=range(npa_per_dep),obs=0).values; y0=dst0.y.isel(traj=range(npa_per_dep),obs=0)\n",
    "            xmin=x0.min();xmax=x0.max();ymin=y0.min();ymax=y0.max()\n",
    "            extend_grid=10 #so from particle min max positions extend grid 10*dx (to not have problems with convolution)\n",
    "            xgrid=np.arange(xmin-dx*1e3*extend_grid,xmax+dx*1e3*(extend_grid+1),dx*1e3,dtype='float32')\n",
    "            ygrid=np.arange(ymin-dy*1e3*extend_grid,ymax+dy*1e3*(extend_grid+1),dy*1e3,dtype='float32')\n",
    "            xgrid0,ygrid0=np.meshgrid(xgrid,ygrid)\n",
    "            points=np.array([x0,y0]).T\n",
    "            tdep_ini=dst0.time.isel(obs=0,traj=ini_dep*npa_per_dep).values #initial date of deployment for this year\n",
    "        if  i==len(files_track_paths)-1:\n",
    "            tdep_end=dst0.time.isel(obs=0,traj=(end_dep+1)*npa_per_dep-1).values #final date of deployment for this year\n",
    "        #\n",
    "        # save the 1st displacements for all the deployments of this month-------\n",
    "        deploys=np.arange(npa_per_dep*ini_dep,npa_per_dep*(end_dep+1))  \n",
    "        #net displacement from intial time of realese until the it time\n",
    "        dxx=(dst0.x.isel(traj=deploys,obs=[0,it+1]).diff(\"obs\")/1e3).isel(obs=0)\n",
    "        dyy=(dst0.y.isel(traj=deploys,obs=[0,it+1]).diff(\"obs\")/1e3).isel(obs=0)\n",
    "        #\n",
    "        #grid data with nearest----\n",
    "        #it is faster than our gridding method and the same results \n",
    "        ntt=int(len(dxx)/npa_per_dep)\n",
    "        dx_grid0=np.reshape(dxx.values,(ntt,npa_per_dep)) #(deploys,npa_per_dep)\n",
    "        dx_grid0 = np.moveaxis(griddata(points, dx_grid0.T, (xgrid0, ygrid0), method='nearest'),-1,0)\n",
    "        dy_grid0=np.reshape(dyy.values,(ntt,npa_per_dep))\n",
    "        dy_grid0= np.moveaxis(griddata(points, dy_grid0.T, (xgrid0, ygrid0), method='nearest'),-1,0)\n",
    "        #check no nans in gridding\n",
    "        nonan.append(np.sum(np.isnan(dx_grid0))+np.sum(np.isnan(dy_grid0)))\n",
    "        #now put nan to the values that grid data put to the regions out DWS domain due to the nearest method\n",
    "        _,_,mask_par=gridding_particles(dxx[range(npa_per_dep)].values,x0,y0)\n",
    "        mask_par[np.isfinite(mask_par)]=1\n",
    "        dx_grid0*=mask_par; dy_grid0*=mask_par\n",
    "        #initial time of the above deployment, and next time\n",
    "        #t0=dst0.time.isel(obs=0,traj=np.arange(ini_dep,end_dep+1)*npa_per_dep).values\n",
    "        #t1=dst0.time.isel(obs=it+1,traj=np.arange(ini_dep,end_dep+1)*npa_per_dep).values\n",
    "        #\n",
    "        #save data\n",
    "        dx_grid.append(dx_grid0); dy_grid.append(dy_grid0)\n",
    "\n",
    "    print(np.sum(np.array(nonan))) #should be always 0, so no nan in original data\n",
    "\n",
    "    #Saving all the months in 1 file for this year-----\n",
    "    #\n",
    "    t_dep=np.arange(tdep_ini,tdep_end+np.timedelta64(1,'s'),m2,dtype='datetime64[s]') #only for this year\n",
    "    dx_grid=np.concatenate(dx_grid,axis=0) #(time_dep,y,x)\n",
    "    dy_grid=np.concatenate(dy_grid,axis=0)\n",
    "\n",
    "    dsout = xr.Dataset()\n",
    "    #global coords and attrs---\n",
    "    dsout.coords[\"time\"] = t_dep\n",
    "    dsout[\"time\"].attrs['description'] = 'initial date of deployments, values every M2'\n",
    "    dsout.coords[\"y\"] = ygrid\n",
    "    dsout[\"y\"].attrs['description'] = 'y-position in meter'\n",
    "    dsout.coords[\"x\"] = xgrid\n",
    "    dsout[\"x\"].attrs['description'] = 'x-position in meter'\n",
    "    #\n",
    "    dsout.attrs[\"year_of_deployments\"] = f\"{year}\"\n",
    "    dsout.attrs[\"npar\"] = f\"number of particles per deployment = {npa_per_dep}\"\n",
    "    #\n",
    "    #variables---\n",
    "    #\n",
    "    dsout[\"it\"] = it+1 #\"f{it+1}\"\n",
    "    dsout[\"it\"].attrs['long_name'] = 'net displacement between [t0, t0+it*M2]'\n",
    "    dsout[\"m2\"] = m2 #\"f{m2}\"\n",
    "    dsout[\"m2\"].attrs['long_name'] = 'm2 tidal period in seconds'\n",
    "    #\n",
    "    dsout[\"dx\"] = ((\"time\",\"y\",\"x\"),dx_grid)\n",
    "    dsout[\"dx\"].attrs['long_name'] = 'net displacement along x-axis'\n",
    "    #dsout[\"dx\"].attrs['description'] = 'rt computed with the first crossing. NaN for stuck particles'\n",
    "    dsout[\"dx\"].attrs['units'] = 'm'\n",
    "    #\n",
    "    dsout[\"dy\"] = ((\"time\",\"y\",\"x\"),dy_grid)\n",
    "    dsout[\"dy\"].attrs['long_name'] = 'net displacement along y-axis'\n",
    "    #dsout[\"dy\"].attrs['description'] = 'rt computed with the first crossing. NaN for stuck particles'\n",
    "    dsout[\"dy\"].attrs['units'] = 'm'\n",
    "    #\n",
    "    file_out_nc=f\"{year}_net_displacement_during_{it+1}M2_for_convlstm.nc\"\n",
    "    dir_out_nc=dir_post_proc_data+dir_net_displacement\n",
    "    dsout.to_netcdf(dir_out_nc+file_out_nc)\n",
    "    dsout.close(); del dsout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
